# プロダクトセキュリティにおける現代の認証・認可の包括的分析

---

## Part I: 基盤となる認証プロトコル (OAuth 2.0 & OpenID Connect)

現代のデジタルエコシステムにおいて、アプリケーション間の安全なデータ連携とユーザーアイデンティティの検証は、プロダクトセキュリティの根幹をなす要素です。このセクションでは、その中核を担う二つのプロトコル、**OAuth 2.0**と**OpenID Connect (OIDC)**について、その基本原則から最新のベストプラクティス、潜在的リスクに至るまでを深く掘り下げ、堅牢な認証・認可基盤を構築するための技術的洞察を提供します。

### 1.1. 中核となる原則: 認可と認証の共生関係

認証と認可は密接に関連していますが、その目的は明確に異なります。この違いを理解することは、セキュアなシステムを設計する上での第一歩です。

#### 1.1.1. OAuth 2.0 (RFC 6749): 認可フレームワーク

**OAuth 2.0**は、認証プロトコルではなく、**委任認可（Delegated Authorization）**のためのフレームワークです。その本質的な問いは、「このアプリケーションは、ユーザーの代わりに何をすることができますか？」という点にあります。例えば、ある写真編集アプリケーションが、ユーザーのGoogle Photosに保存されている写真にアクセスしたい場合、ユーザーは自身のGoogleアカウントのパスワードを写真編集アプリに渡すことなく、写真へのアクセス権限のみを安全に委任できます。

このフレームワークは、4つの主要な**役割（Role）**によって構成されます。

*   **リソースオーナー (Resource Owner):** 保護されたリソース（例: 写真データ）へのアクセスを許可できるエンティティ。通常はエンドユーザーです。
*   **クライアント (Client):** リソースオーナーの代理として、保護されたリソースへのアクセスを要求するアプリケーション（例: 写真編集アプリ）。
*   **認可サーバー (Authorization Server - AS):** リソースオーナーを認証し、その同意を得た上で、クライアントに**アクセストークン**を発行するサーバー（例: Googleの認可サーバー）。
*   **リソースサーバー (Resource Server - RS):** 保護されたリソースをホストし、アクセストークンを提示したクライアントからのリクエストを受け付け、応答するサーバー（例: Google PhotosのAPIサーバー）。

#### 1.1.2. OpenID Connect (OIDC) 1.0: アイデンティティレイヤー

**OpenID Connect (OIDC)は、OAuth 2.0プロトコルの上に構築された、薄いアイデンティティレイヤー**です。OIDCの目的は、「このユーザーは誰ですか？」という問いに答えることです。OAuth 2.0が提供する認可フローを利用しつつ、認証に関する標準化された情報をやり取りする仕組みを追加します。

OIDCは、主に以下の要素をOAuth 2.0に加えることでこれを実現します。

*   **IDトークン (ID Token):** ユーザーの認証に関する情報（クレーム）を含む**JSON Web Token (JWT)**。これは、クライアントがユーザーのアイデンティティを検証するための「証明書」として機能します。
*   **UserInfoエンドポイント:** IDトークンに含まれる情報に加え、より詳細なユーザープロフィール情報を取得するためのAPIエンドポイント。
*   **標準化されたスコープ:** openid、profile、emailなど、アイデンティティ情報を要求するための標準スコープ。
*   **ディスカバリメカニズム:** /.well-known/openid-configuration という既知のエンドポイントを通じて、認可サーバーのエンドポイントURLや対応機能、公開鍵情報などを動的に取得する仕組み。

#### 1.1.3. 決定的な違い

最も重要な点は、OAuth 2.0単体で認証を実装することは、セキュリティ上のアンチパターンであるということです。アクセストークンはリソースへのアクセス権を示すものに過ぎず、それ自体がユーザー認証を証明するものではありません。OIDCは、**IDトークン**という形で暗号学的に検証可能な認証の証拠を提供し、標準化されたクレームによってユーザー情報を安全に伝達する手段を定義することで、このギャップを埋めます。したがって、現代のフェデレーション認証においては、OIDCの利用が不可欠です。

### 1.2. 現代の標準: PKCE付き認可コードフロー

現在、ユーザーが介在するWebアプリケーションやモバイルアプリケーションにおいて、最も安全で推奨されるフローが**PKCE (Proof Key for Code Exchange) 付き認可コードフロー**です。

#### 1.2.1. フローのウォークスルー

このフローは、機密情報であるトークンがユーザーのブラウザ（ユーザーエージェント）を経由することなく、クライアントのバックエンドと認可サーバー間で直接交換されるため、高いセキュリティを誇ります。

1.  **クライアントによる初期化:** クライアントアプリケーションは、まず暗号学的にランダムな文字列である**コード検証子 (code_verifier)**を生成します。次に、code_verifierをSHA-256でハッシュ化し、Base64URLエンコードした**コードチャレンジ (code_challenge)**を生成します。
2.  **認可リクエスト:** クライアントはユーザーを認可サーバーの/authorizeエンドポイントにリダイレクトさせます。このとき、response_type=code、client_id、redirect_uri、scope、stateといった標準パラメータに加え、生成したcode_challengeとcode_challenge_method=S256をクエリパラメータに含めます。
3.  **ユーザーの認証と同意:** ユーザーは認可サーバー上で認証（例: IDとパスワードでログイン）を行い、クライアントが要求している権限（スコープ）に対して同意を与えます。
4.  **認可コードの払い出し:** 認可サーバーは、ユーザーをクライアントのredirect_uriにリダイレクトさせます。このリダイレクトURLのクエリパラメータには、短命の**認可コード (authorization code)**と、CSRF対策のためのstateパラメータが含まれます。
5.  **トークン交換:** クライアントのバックエンドサーバーは、受け取った認可コードを使い、認可サーバーの/tokenエンドポイントに対して直接リクエストを送信します。このリクエストには、認可コード、client_id、client_secret（コンフィデンシャルクライアントの場合）、そしてステップ1で生成したオリジナルのcode_verifierが含まれます。
6.  **トークンの発行:** 認可サーバーは、受け取ったcode_verifierをハッシュ化し、ステップ2で受け取って保存しておいたcode_challengeと照合します。一致した場合、認可コードが正当なクライアントから送られたものだと確認できるため、**アクセストークン**、**リフレッシュトークン**、そしてopenidスコープが要求されていれば**IDトークン**を発行します。

#### 1.2.2. PKCE (RFC 7636) の役割

**PKCE**は、もともとclient_secretを安全に保持できない**パブリッククライアント**（SPAやモバイルアプリなど）のために考案されましたが、現在では**コンフィデンシャルクライアント**（サーバーサイドWebアプリ）を含むすべてのクライアントタイプでの利用がベストプラクティスとされています。

その主な目的は、**認可コード傍受攻撃（Authorization Code Interception Attack）**を緩和することです。この攻撃では、悪意のあるアプリが正規のアプリになりすまして認可コードを傍受し、アクセストークンを不正に取得しようとします。PKCEは、トークン交換時にcode_verifierという「一度限りの秘密情報」を要求することで、この攻撃を防ぎます。たとえ攻撃者が認可コードを盗んだとしても、code_verifierを知らない限りトークンと交換することはできません。これにより、認可リクエストとトークンリクエストが暗号学的に紐付けられ、フロー全体のセキュリティが大幅に向上します。

このメカニズムの普及は、現代のアプリケーションアーキテクチャの変遷と密接に関連しています。Single-Page Application (SPA)の台頭は、クライアントサイドのJavaScriptがclient_secretを安全に保持できないという新たな課題を生み出しました。当初、この問題を回避するためにインプリシットフローが考案されましたが、後述するようにセキュリティ上の欠陥を抱えていました。PKCEは、この認可コード傍受という根本的な問題を解決することで、より安全な認可コードフローをSPAのようなパブリッククライアントでも利用可能にしました。結果として、機密性の高いトークンがブラウザに一切露出することなく、安全にバックエンド間で受け渡されるモデルが確立され、業界標準となったのです。

**Table 1: Comparison of OAuth 2.0 Grant Types**

| Grant Type | response_type | Use Case | Client Type | Security Profile | Tokens Issued |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **Authorization Code with PKCE** | code | Web App, SPA, Mobile App | Confidential & Public | **Highest** | Access, Refresh, ID |
| **Authorization Code** | code | Web App | Confidential | High | Access, Refresh, ID |
| **Client Credentials** | N/A (Token Endpoint) | Machine-to-Machine (M2M) | Confidential | High | Access |
| **Refresh Token** | N/A (Token Endpoint) | All (except Implicit) | Confidential & Public | High | Access, Refresh |
| **Implicit (Legacy)** | token, id_token token | Legacy SPAs | Public | **Low (Deprecated)** | Access, ID (No Refresh) |
| **Resource Owner Password (Legacy)** | N/A (Token Endpoint) | Trusted first-party apps | Confidential | **Low (Deprecated)** | Access, Refresh |

### 1.3. レガシーとその教訓: インプリシットフロー（と非推奨の理由）

かつてSPAで広く使われた**インプリシットフロー**は、現在ではセキュリティ上の懸念から非推奨とされています。

#### 1.3.1. 動作の仕組み

インプリシットフローは、response_type=tokenを指定することで、認可サーバーがアクセストークンを認可コードを介さずに、直接リダイレクトURIの**URLフラグメント**（#以降の部分）に含めてクライアントに返すフローです。バックエンドサーバーを介したトークン交換ステップが不要なため、実装がシンプルでした。

#### 1.3.2. 内在する脆弱性

このシンプルさの代償として、インプリシットフローには複数の深刻な脆弱性が存在します。

*   **トークン漏洩:** アクセストークンがブラウザのURLに直接露出するため、ブラウザの履歴、ウェブサーバーのログ、そしてリファラヘッダー（Referer）を介して第三者に漏洩するリスクが非常に高いです。
*   **リフレッシュトークンの非サポート:** このフローではリフレッシュトークンが発行されないため、セッションを維持するには、有効期間の長い（したがってリスクの高い）アクセストークンを発行するか、定期的にユーザーに再認証を強いる必要があり、ユーザビリティが損なわれます。
*   **XSS攻撃の影響拡大:** Cross-Site Scripting (XSS) 脆弱性が存在する場合、攻撃者は容易にURLフラグメントからアクセストークンを窃取し、ユーザーになりすますことができます。

#### 1.3.3. 業界のコンセンサス

これらのリスクから、IETFのベストプラクティスや次世代のOAuth 2.1仕様では、インプリシットフローの使用は明確に禁止されています。すべてのインプリシットフローの実装は、PKCE付き認可コードフローに移行することが強く推奨されます。

### 1.4. 制御の三要素: スコープ、IDトークン、アクセストークン

OAuth/OIDCフローにおいて、3つの異なる概念、**スコープ**、**IDトークン**、**アクセストークン**は、それぞれが明確な役割を担っています。

*   **スコープ (Scopes):** 権限の定義。スコープは、クライアントがリソースオーナーに要求する権限の範囲を定義する文字列です（例: profile, email, read:files）。これにより、クライアントは必要最小限の権限のみを要求する**最小権限の原則**を実践できます。ユーザーは同意画面で、どの権限を許可するかを確認できます。
*   **IDトークン (ID Tokens - OIDC):** クライアントのための認証証明。IDトークンは、ユーザー自身（sub, name, emailなど）と認証イベント（iss, aud, exp, iatなど）に関する**クレーム**を含むJWTです。これは、**クライアントアプリケーションが消費し、検証するためだけ**のものです。IDトークンをリソースサーバーへのアクセスのためにベアラートークンとして送信してはなりません。
*   **アクセストークン (Access Tokens - OAuth 2.0):** リソースへの鍵。アクセストークンは、クライアントが保護されたリソースにアクセスするために**リソースサーバーに提示する**資格情報です。形式はリソースサーバーが理解できればよく、不透明な文字列（Opaque String）でもJWTでも構いません。その内容はリソースサーバーが消費するためのものであり、クライアントが内容を解釈すべきではありません。

### 1.5. リスクと対策: 一般的なOAuth/OIDC攻撃ベクトル

OAuth/OIDCは強力なフレームワークですが、実装の誤りは深刻な脆弱性につながります。

*   **不十分なredirect_uri検証:** これは最も重大な脆弱性の一つです。認可サーバーがredirect_uriの検証を怠るか、ワイルドカードや部分一致のような緩い検証を許している場合、攻撃者はユーザーを騙して、認可コードやアクセストークンを攻撃者の制御下にあるサーバーに送信させることができます。
    *   **対策:** 認可サーバーは、事前に登録されたredirect_uriのリストと**完全一致**するURIのみを許可しなければなりません。ワイルドカード、パスのプレフィックス一致、クエリパラメータの許容は極めて危険です。
        redirect_uriは、OAuthの信頼モデルにおける中心的なセキュリティ境界であり、その検証ロジックの不備はプロトコル全体の安全性を根底から覆します。
*   **クライアントサイドのCSRF:** 攻撃者は、認証済みのユーザーを騙して、攻撃者が開始したOAuthフローを完了させることができます。これにより、被害者のクライアントアプリケーションアカウントが、攻撃者のIdPアカウントに紐付けられてしまう可能性があります。この攻撃の詳細は、[[application-layer-security-controls-analysis|アプリケーションレイヤーのセキュリティ統制]]で解説するCSRFの概念と関連しています。
    *   **対策:** クライアントは、推測不可能でユーザーセッションに紐付いたstateパラメータを必ず使用し、リダイレクト時に返された値がリクエスト時の値と一致することを検証しなければなりません。これはOAuthフローにおけるCSRFトークンとして機能します。
*   **オープンリダイレクトを介した認可コード漏洩:** クライアントアプリケーションのドメイン内にオープンリダイレクト脆弱性が存在する場合、攻撃者はそれを悪用して、認可サーバーのredirect_uri検証をパスしつつ、最終的にユーザー（とクエリパラメータ内の認可コード）を悪意のあるサイトに転送する、巧妙なredirect_uriを構築できます。
    *   **対策:** クライアントアプリケーションからオープンリダイレクト脆弱性を完全に排除することが不可欠です。redirect_uriは、OAuthレスポンスの処理のみを行う専用の静的エンドポイントを指すべきです。
*   **動的クライアント登録を介したSSRF:** これは高度な攻撃で、攻撃者が悪意のあるクライアントを認可サーバーに登録する際に、logo_uriやjwks_uriといったURLベースのパラメータを利用して、認可サーバー自身に内部ネットワークや任意の外部サーバーへのリクエストを強制させるものです。
    *   **対策:** 認可サーバーは、クライアント登録時にすべてのURLベースのパラメータを厳格に検証し、アウトバウンドリクエストを制限するネットワーク制御を導入し、取得したリソースのコンテントタイプを検証する必要があります。

### 1.6. 将来展望: OAuth 2.1の登場

**OAuth 2.1**は、全く新しいプロトコルではなく、これまでのベストプラクティスを成文化し、安全でないオプションを排除することを目的とした、次世代の仕様です。

*   **主要な変更点:**
    *   PKCEは、認可コードフローを使用する**すべてのクライアントで必須**となります。
    *   インプリシットフロー（response_type=token）は**正式に廃止**されます。
    *   リダイレクトURIは**完全文字列一致**で比較されなければなりません。
    *   リソースオーナー・パスワード・クレデンシャル・グラントは**廃止**されます。
    *   クエリ文字列でのベアラートークンの送信は**禁止**されます。
*   **意味合い:** OAuth 2.1は、開発者が誤った選択をする余地を減らし、「セキュア・バイ・デフォルト」な実装へと導くことで、OAuthエコシステム全体のセキュリティベースラインを向上させることを目指しています。

---

## Part II: アクセスの通貨 - トークンと鍵の管理

認証プロトコルによって発行されるトークンは、アクセス権そのものです。このセクションでは、これらの暗号学的アーティファクト、特にJWTの構造、署名、ライフサイクル管理、そしてそれらを支える秘密鍵の安全な保管方法について詳述します。

### 2.1. JSON Web Token (JWT) の解剖学

**JSON Web Token (JWT)** は、情報をJSONオブジェクトとして安全にやり取りするためのオープンスタンダード（RFC 7519）です。そのコンパクトさと自己完結性から、IDトークンやアクセストークンとして広く利用されています。

#### 2.1.1. 構造 (RFC 7519)

JWTは、ドット（.）で区切られた3つのBase64Urlエンコードされたパートから構成されます。

*   **ヘッダー (Header):** トークンのメタデータを含みます。主に、トークンのタイプ（typ: "JWT"）と、使用される署名アルゴリズム（alg: "RS256"など）が格納されます。
*   **ペイロード (Payload):** **クレーム（Claims）**、すなわちエンティティに関する表明を含みます。クレームには3つの種類があります。
    *   **登録済みクレーム (Registered Claims):** iss（発行者）、sub（主題）、aud（対象者）、exp（有効期限）、iat（発行日時）、jti（JWT ID）など、仕様で定義された標準的なクレーム。
    *   **公開クレーム (Public Claims):** 衝突を避けるためにIANAのJWTレジストリに登録されるか、URI形式の名前空間を持つクレーム。
    *   プライベートクレーム (Private Claims): 発行者と消費者の間で合意された独自のクレーム。
        重要なのは、ペイロードはエンコードされているだけで暗号化されていないため、誰でも内容を読むことができるという点です。機密情報をペイロードに含めてはなりません。
*   **署名 (Signature):** トークンの**完全性**（改ざんされていないこと）と**認証性**（正当な発行者によって署名されたこと）を保証する暗号学的な証明です。署名は、エンコードされたヘッダーとペイロード、そして秘密鍵をalgで指定されたアルゴリズムで処理することで生成されます。例: HMACSHA256(base64UrlEncode(header) + "." + base64UrlEncode(payload), secret)。

#### 2.1.2. アクセストークンとしてのJWT (RFC 9068)

OAuth 2.0のアクセストークンとしてJWTを使用する場合のプロファイルを定義したRFC 9068も存在します。これは、リソースサーバー間での相互運用性を高めるために、iss、exp、aud、subといったクレームを標準化するものです。

### 2.2. 署名のジレンマ: HS256 vs. RS256

JWTの署名アルゴリズムの選択は、システムのアーキテクチャと信頼モデルに直結する重要な決定です。

#### 2.2.1. HS256 (HMAC with SHA-256): 対称鍵署名

*   **メカニズム:** 署名と検証の両方に、単一の**共有秘密鍵**を使用します。
*   **ユースケース:** トークンの発行者と検証者が同一のエンティティであるか、密結合したサービス群（例: モノリシックアプリケーション）で、秘密鍵を安全に共有できる場合に適しています。
*   **長所:** RS256に比べて高速で、実装がシンプルです。
*   **短所:** 鍵管理が最大の課題です。秘密鍵を複数のサービスで共有する必要があり、漏洩リスクが増大します。また、検証者（サービス）が侵害されると、そのサービスはトークンを偽造することも可能になってしまいます。

#### 2.2.2. RS256 (RSA Signature with SHA-256): 非対称鍵署名

*   **メカニズム:** 署名には**秘密鍵**を、検証には対となる**公開鍵**を使用します。
*   **ユースケース:** マイクロサービスやサードパーティAPIのような、現代の**分散システムにおける推奨標準**です。秘密鍵は署名サービス（認可サーバー）内に完全に隔離し、公開鍵は
    jwks_uriエンドポイントなどを通じて広範に配布できます。
*   **長所:** 優れたセキュリティモデルを提供します。検証者（公開鍵を持つサービス）が侵害されても、トークンの偽造はできません。信頼関係のない多数のコンシューマをサポートできます。
*   **短所:** HS256よりも処理が遅く、鍵管理がより複雑になります。

この選択は単なる技術的な詳細ではなく、システムの信頼モデルそのものを反映します。マイクロサービスの台頭は、多数の独立したサービスがトークンを検証する必要性を生み出しました。HS256を使用すると、すべてのサービスが同じ強力な秘密鍵を共有する「秘密のメッシュ」構造となり、一つのサービスの侵害がシステム全体の侵害につながる脆弱なモデルとなります。対照的に、RS256は、秘密鍵を単一の堅牢な認可サーバーに限定し、公開鍵のみを配布する「ハブ・アンド・スポーク」型の信頼モデルを強制します。このアーキテクチャ上の圧力により、RS256は現代の分散アプリケーションにとって、論理的かつスケーラブルな唯一の選択肢となっています。

**Table 2: JWT Signing Algorithms - HS256 vs. RS256**

| Feature | HS256 (Symmetric) | RS256 (Asymmetric) |
| :--- | :--- | :--- |
| **Cryptography Type** | Symmetric (共有秘密鍵) | Asymmetric (公開鍵/秘密鍵ペア) |
| **Key(s) Used** | 1つの共有秘密鍵 | 1つの秘密鍵 (署名用), 1つの公開鍵 (検証用) |
| **Key Management** | シンプルだが、鍵の共有がリスク。 | 複雑だが、秘密鍵を安全に隔離可能。 |
| **Performance** | 高速 | 比較的低速 |
| **Security Model** | 検証者が侵害されるとトークンを偽造可能。 | 検証者が侵害されてもトークン偽造は不可。 |
| **Recommended Use Case** | モノリシックアプリ、単一の信頼境界内。 | **マイクロサービス、分散システム、サードパーティ連携。** |

### 2.3. 一般的なJWTの脆弱性と防御策

JWTの実装や検証ロジックの不備は、深刻なセキュリティホールとなり得ます。

#### 2.3.1. アルゴリズム操作

*   **alg:none攻撃:** 攻撃者がヘッダーを{"alg":"none"}に変更し、署名部分を削除する攻撃。脆弱なライブラリは、署名検証を完全にスキップしてこのトークンを受け入れてしまう可能性があります。
    *   **防御策:** 検証サーバーは、許可するアルゴリズムの**厳格なホワイトリスト**（例: `['RS256']`）を持ち、トークンから送られてくるalgヘッダーの値を決して信用してはなりません。
*   **アルゴリズム混乱攻撃 (RS256 to HS256):** 非常に巧妙かつ破壊的な攻撃です。攻撃者は、RS256で署名されたトークンの公開鍵を取得し、ペイロードを改ざんした新しいトークンを作成します。その際、ヘッダーのalgをHS256に変更し、HMACの秘密鍵として**本来の公開鍵**を使用して署名します。脆弱なライブラリは、"RS256"の検証のために公開鍵を取得しますが、それを"HS256"の秘密鍵として誤用し、結果として検証に成功してしまいます。
    *   **防御策:** サーバーはアルゴリズムを検証するだけでなく、そのアルゴリズムに期待される鍵のタイプ（RS256なら非対称鍵、HS256なら対称鍵）と提供された鍵が一致することを確認しなければなりません。

#### 2.3.2. 鍵のインジェクションと誤用

*   **kid (Key ID) パラメータインジェクション:** kidヘッダーは、サーバーが検証にどの鍵を使用すべきかを示すためのものです。サーバーがこの値をファイルパスやデータベースクエリの構築に無防備に使用すると、パストラバーサル、SQLインジェクション、コマンドインジェクションにつながる可能性があります。
    *   **防御策:** kidの値を信頼できないユーザー入力として扱い、厳格にサニタイズし、事前に承認された鍵のマップやデータベースから鍵をルックアップするための識別子としてのみ使用します。ファイルパスやSQLクエリの直接構築には決して使用してはなりません。
*   **jku (JWK Set URL) ヘッダーの誤用:** jkuヘッダーは、検証用のJWKセットを見つけることができるURLを指します。攻撃者は自身の鍵で署名した偽のトークンを作成し、jkuを自身の公開鍵をホストする悪意のあるサーバーのURLに変更することができます。
    *   **防御策:** サーバーは、信頼できるjkuドメインの厳格なホワイトリストを維持し、トークンで提供された任意のURLから鍵を取得してはなりません。

#### 2.3.3. 脆弱な秘密鍵のブルートフォース

HS256を使用する場合、"secret"や"password"のような脆弱または推測可能な秘密鍵を使用すると、攻撃者によってオフラインでブルートフォース攻撃を受ける可能性があります。

*   **防御策:** 高いエントロピーを持つ、暗号学的にランダムな秘密鍵を使用します。分散システムの場合は、この問題を根本的に回避するためにRS256を使用することが最善です。

### 2.4. セッションの維持: リフレッシュトークンのローテーション

アクセストークンは短命（例: 15分）に設定するのがベストプラクティスですが、ユーザーに頻繁な再ログインを強いることなくセッションを維持するためにリフレッシュトークンが使用されます。

#### 2.4.1. 静的なリフレッシュトークンの問題点

長命のリフレッシュトークンが一度漏洩すると、攻撃者はそれが失効するか手動で無効化されるまで、ユーザーアカウントへの永続的なアクセス権を得てしまいます。

#### 2.4.2. 解決策: ローテーションと再利用検知

**リフレッシュトークン・ローテーション**は、このリスクを劇的に低減する重要なベストプラクティスです。

1.  クライアントがリフレッシュトークン（RT_1）を使用して新しいアクセストークンを要求すると、サーバーはRT_1を検証します。
2.  サーバーは新しいアクセストークン（AT_2）と**新しいリフレッシュトークン（RT_2）**を発行します。
3.  サーバーは使用済みのRT_1を**即座に無効化**します。
4.  後日、攻撃者が盗んだRT_1を再利用（リプレイ）しようとすると、サーバーは既に使用済みのトークンが提示されたことを検知します。これは、トークンが侵害されたことを示す強力なシグナルです。
5.  再利用を検知したサーバーは、元のログインから派生した**トークンファミリー全体を無効化**し、正規のユーザーに再認証を強制すべきです。

このメカニズムは、単なるセキュリティ対策以上の価値を持ちます。静的なトークンモデルでは、トークンの盗難は検知不能な受動的な脆弱性です。セキュリティチームは、ユーザーからの不審なアクティビティ報告を待つしかありません。しかし、リフレッシュトークン・ローテーションを導入することで、この受動的な脆弱性が、**能動的かつ高忠実度なセキュリティイベント**に変わります。トークンの再利用試行は、特定のトークンファミリーが侵害されたことを示す「カナリア」として機能します。これにより、システムは受動的な防御から脱却し、侵害をプロアクティブに検知して、関連セッションの即時無効化やアカウントのロックダウンといった自動化されたインシデントレスポンスを発動できます。リフレッシュメカニズム自体が、分散型の侵入検知センサーとして機能するのです。

実装にあたっては、正規のクライアントがネットワークの遅延などによって同じトークンで同時にリクエストを送信してしまう競合状態を処理するための**猶予期間（Grace Period）**を設けることや、トークンのメタデータ（使用状況など）を安全に保存するためのサーバーサイドストレージ（例: Redis）の利用が重要です。

### 2.5. 最重要機密の保護: Secrets Management

署名鍵やclient_secretは、認証システムにおける最重要機密情報（クラウンジュエル）です。これらをソースコードにハードコーディングしたり、平文で設定ファイルに記述したりすることは絶対に許されません。これらの機密情報の安全な管理手法については、[[data-layer-security-analysis|データレイヤーのセキュリティ]]で詳述する**Key Management Service (KMS)**の利用が不可欠です。

#### 2.5.1. 専用サービスの利用

ベストプラクティスは、**AWS Secrets Manager**、**Azure Key Vault**、**Google Secret Manager**のような専用のシークレット管理サービスを利用することです。

#### 2.5.2. 主要な機能とベストプラクティス

*   **一元化された暗号化ストレージ:** シークレットは保存時に暗号化（at-rest encryption）されます。多くの場合、**Hardware Security Module (HSM)やAWS KMSのようなサービスを利用したエンベロープ暗号化**が用いられます。
*   **詳細なアクセス制御:** IAMポリシーなどを用いて最小権限の原則を徹底し、特定のサービスやロールのみが特定のシークレットにアクセスできるように制限します。
*   **自動ローテーション:** シークレットや鍵をスケジュールに基づいて自動的にローテーションさせることで、万が一鍵が漏洩した場合の被害範囲を限定します。
*   **監査ログ:** AWS CloudTrailなどのログサービスと連携し、シークレットへのすべてのアクセス試行を監視・監査します。

---

## Part III: エンゲージメントのルール - 認可とアイデンティティマッピング

このセクションでは、「ユーザーは誰か？」という認証の問いから、「そのユーザーは何をすることが許されているか？」という認可の問いへと焦点を移します。また、外部のアイデンティティを自社サービスに安全に紐付ける方法についても解説します。

### 3.1. 役割ベースのアクセス制御 (RBAC)

#### 3.1.1. 原則

**役割ベースのアクセス制御 (Role-Based Access Control - RBAC)** は、権限（Permission）を役割（Role）に割り当て、ユーザーにその役割を割り当てることでアクセスを制御するモデルです。ユーザーのアクセス権は、そのユーザーが持つ役割（例: 「管理者」「編集者」「閲覧者」）によって決まります。

#### 3.1.2. 実装

実装は比較的直感的です。データベースにrolesテーブル、permissionsテーブル、そして両者を紐付ける中間テーブルを作成し、ユーザーテーブルにrole_idを持たせるのが一般的です。あるいは、JWTのプライベートクレームとして"roles": ["admin"]のように役割情報を含め、リソースサーバー側でそのクレームに基づいてアクセスを判断する方法もあります。

#### 3.1.3. 長所と短所

RBACの最大の利点は、そのシンプルさと管理のしやすさです。多くのアプリケーションにとって、RBACは十分なアクセス制御を提供します。しかし、システムの要件が複雑化するにつれて、特定の権限の組み合わせを持つ多数の役割を作成する必要が生じ、**ロール爆発（Role Explosion）**と呼ばれる管理不能な状態に陥る可能性があります。

### 3.2. 属性ベースのアクセス制御 (ABAC)

#### 3.2.1. 原則

**属性ベースのアクセス制御 (Attribute-Based Access Control - ABAC)** は、より動的で詳細なアクセス制御モデルです。アクセス判断は、ユーザー、リソース、アクション、そして環境（コンテキスト）の**属性（Attribute）**を組み合わせたポリシーに基づいて行われます。

#### 3.2.2. 実装

ABACのポリシーは、「department: 'Finance'という属性を持つユーザーは、type: 'financial_report'という属性を持つリソースに対して、action: 'view'を、午前9時から午後5時の間（環境属性）に限り許可する」といった形で表現されます。これにより、RBACでは困難な、状況に応じた柔軟なアクセス制御が可能になります。

#### 3.2.3. 長所と短所

ABACは非常に強力で柔軟性が高く、ロール爆発を回避できます。一方で、ポリシーの設計、実装、テスト、デバッグがRBACよりも格段に複雑になるという欠点があります。

アプリケーションのライフサイクルにおいて、認可モデルは静的なものではありません。多くの場合、アプリケーションは初期段階ではシンプルなRBACで十分ですが、ビジネスの成長と機能の複雑化に伴い、より詳細な制御が求められるようになります。「EUの管理者は米国の顧客データを見てはならない」「契約社員は業務時間内のみアクセス可能」といった要件は、RBACでモデル化しようとするとロール爆発を引き起こします。このロール爆発こそが、ABACへの移行を促す強力な推進力となります。したがって、アーキテクトは将来的なABACへの拡張を見越して、初期のRBACシステムを設計することが賢明です。このRBACからABACへの進化は、アプリケーションが特定のビジネス的成熟度に達したことを示す代理指標と見なすことができます。

**Table 3: Authorization Models - RBAC vs. ABAC**

| Feature | Role-Based Access Control (RBAC) | Attribute-Based Access Control (ABAC) |
| :--- | :--- | :--- |
| **Policy Granularity** | Coarse-grained (粗粒度) | Fine-grained (細粒度) |
| **Flexibility** | Static, role-based | Dynamic, context-aware |
| **Implementation Complexity** | Low to Medium | High |
| **Performance Overhead** | Low | Potentially higher due to complex policy evaluation |
| **Typical Use Case** | シンプルなCMS、社内ツール | マルチテナントSaaS、金融、ヘルスケアなど、複雑なコンプライアンス要件を持つシステム |

### 3.3. 安全なアイデンティティフェデレーション: subクレームのマッピング

外部のIdP（例: Google, Okta）を利用したログイン機能（アイデンティティフェデレーション）を実装する際、外部のユーザー識別子を自社サービスのユーザーIDと安全に紐付けることが極めて重要です。

#### 3.3.1. sub (Subject) クレーム

**sub（Subject）クレーム**は、アイデンティティにおいて最も重要なクレームです。これは、**発行者（Issuer）のコンテキスト内で**、ユーザーを一意に識別するための、決して再割り当てされない識別子です。

subクレームはケースセンシティブな文字列であり、その内容に意味を求めず、不透明な識別子として扱うべきです。

#### 3.3.2. 課題

ユーザーがGoogleでログインすると、アプリケーションはsubクレームとして"112...789"のような値を受け取ります。アプリケーションは、この外部識別子を自身の内部ユーザーレコードに安全に紐付ける必要があります。

#### 3.3.3. ベストプラクティス: マッピングテーブル

最も堅牢で安全なアプローチは、アプリケーションのデータベースに専用のマッピングテーブル（例: external_identities）を作成することです。

*   このテーブルは、(internal_user_id, issuer_url, subject_claim)といったカラムを持つべきです。
*   主キーは(issuer_url, subject_claim)の複合キーとします。これにより、ユーザーは「どの発行者」の「どの識別子」であるかによって一意に識別されます。
*   このアプローチは、アプリケーションの内部ユーザーモデルを外部IdPから疎結合にし、一人のユーザーが複数の外部アイデンティティ（GoogleアカウントとGitHubアカウントなど）を単一の自社アカウントにリンクさせることも可能にします。

#### 3.3.4. セキュリティ上の考慮事項

この実装において、subクレームは発行者内でのみ一意性が保証されることを理解することが不可欠です。Googleが発行するsub="123"と、Oktaが発行するsub="123"は全く別のユーザーを指します。したがって、グローバルに一意なユーザー識別子は、**iss（Issuer）クレームとsubクレームのペア**によって構成されます。システムは常にこのペアを検証し、主キーとして扱わなければなりません。

emailのような変更可能であったり、未検証であったりするクレームをプライマリな識別子として使用することは、アカウントの衝突や乗っ取りにつながる可能性があるため、絶対に避けるべきです。

issとsubのペアこそが、フェデレーションされたアイデンティティにおける不変の「錨（いかり）」なのです。

### 3.4. 将来展望: Subject Identifierの進化

単純な文字列ベースのsubクレームは、一人のユーザーが複数の方法（メール、電話番号、社内IDなど）で識別される複雑なシナリオには不十分です。

*   **sub_id (RFC 9493) の導入:** この課題に対処するため、新しいJWTクレームsub_idが標準化されました。このクレームの値は、複雑なSubject Identifierを表現できるJSONオブジェクトです。
*   **表現形式:** sub_idは、発行者と主題を明示的にペアにするiss_sub形式や、同一主題に対する複数の等価な識別子をリストアップするaliases形式などを含むことができます。
*   **意味合い:** sub_idは、複雑なアイデンティティの相関付けを扱うための標準化された方法を提供します。これは、アイデンティティフェデレーション、アカウントリンク、システム間のユーザー移行といったシナリオで極めて重要であり、アイデンティティの表現を単一の不透明な文字列から、構造化された多面的な表現へと進化させます。

---

## Part IV: アイデンティティの未来 - 新たなトレンドとパラダイム

認証・認可の世界は、静的なモデルから動的でユーザー中心のパラダイムへと急速に進化しています。この最終セクションでは、パスワードの終焉を告げる**Passkeys**、セッションセキュリティをリアルタイム化する**Shared Signals Framework**、そしてアイデンティティの所有権をユーザーに戻す**Decentralized Identity**という、未来を形作る最先端の技術と標準を探求します。

### 4.1. パスワードの終焉: PasskeysとWebAuthn

パスワードに依存した認証は、フィッシング、クレデンシャルスタッフィング、データ漏洩といった数多くの問題に悩まされてきました。**Passkeys**は、この長年の課題に対する決定的な解決策として登場しました。

#### 4.1.1. テクノロジーの核心

*   **WebAuthn (Web Authentication):** W3CとFIDO Allianceによって標準化された、公開鍵暗号方式を利用してウェブ上での認証を行うためのAPIです。認証器（Authenticator）がサイトごとに新しい鍵ペアを生成するため、フィッシング攻撃に対して極めて高い耐性を持ちます。秘密鍵はデバイスから決して離れません。
*   **Passkeysとは何か:** Passkeysは、WebAuthnクレデンシャルの一種であり、特に**発見可能（Discoverable）**かつ**同期可能（Syncable）**という二つの重要な特徴を持ちます。
    *   **発見可能:** 認証器が、どのサイトのクレデンシャルを保持しているかをブラウザに伝えることができます。これにより、ユーザーはユーザー名を入力することなく、利用可能なPasskeyを選択するだけでログインできます。
    *   **同期可能:** Passkeyは、AppleのiCloudキーチェーンやGoogleパスワードマネージャーといったクラウドプロバイダーを介して、ユーザーが所有する複数のデバイス間で安全に同期されます。これにより、デバイスごとに登録する手間が省け、デバイスを紛失した際にもリカバリーが可能となり、ユーザビリティが劇的に向上します。

#### 4.1.2. 動作の仕組み

Passkeyのフローは、クライアントサイドのJavaScript APIと認証器の連携によって実現されます。

1.  **登録 (Registration):** ユーザーがPasskeyの作成を選択すると、Webサイト（Relying Party）はnavigator.credentials.create()を呼び出します。認証器（例: スマートフォンの生体認証機能やYubiKey）は新しい公開鍵と秘密鍵のペアを生成し、Webサイトから送られてきたチャレンジ（ランダムなデータ）に秘密鍵で署名します。公開鍵と署名がWebサイトに送られ、保存されます。
2.  **認証 (Authentication):** ログイン時に、Webサイトはnavigator.credentials.get()を呼び出し、新しいチャレンジを認証器に送ります。認証器はユーザーに本人確認（生体認証やPIN）を求め、保存されている秘密鍵でチャレンジに署名して返します。Webサイトは、保存しておいた公開鍵で署名を検証し、成功すればログインを許可します。

#### 4.1.3. OIDCとの統合

PasskeysはOIDCを置き換えるものではなく、OIDCフローにおける**優れた認証方式**として機能します。Auth0やOktaのようなIdPは、第一認証要素としてPasskeysをサポートするように設定できます。ユーザーがPasskeyでIdPに認証されると、IdPは標準的なOIDCのIDトークンとアクセストークンをクライアントアプリケーションに発行します。これにより、アプリケーション側は既存のOIDC実装を大きく変更することなく、Passkeysの恩恵（高いセキュリティと優れたUX）を受けることができます。

### 4.2. 静的から動的へ: Shared Signals Framework (SSF) と CAEP

従来のセッション管理モデルには、根本的な欠陥がありました。一度発行されたアクセストークンは、有効期限が切れるまで有効であり続けます。その間にユーザーのセキュリティコンテキスト（例: デバイスがマルウェアに感染、不審な場所からのアクセス）が変化しても、トークンは有効なままであり、これが脆弱性の窓口となっていました。

#### 4.2.1. 解決策: リアルタイムのイベントストリーム

この「静的な信頼」の問題を解決するのが、**Shared Signals Framework (SSF)**と**Continuous Access Evaluation Protocol (CAEP)**です。

*   **Shared Signals Framework (SSF):** OpenID Foundationが標準化を進める、信頼されたパーティ間（**Transmitter**と**Receiver**）でセキュリティイベントを通信するための安全なPub/Subフレームワークです。これは通信の「方法論（How）」を定義します。
*   **Continuous Access Evaluation Protocol (CAEP):** SSFの**プロファイル**の一つで、セッションセキュリティに関連する特定のイベントタイプを定義します。これは通信される情報の「内容（What）」を定義します。

#### 4.2.2. 主要なCAEPイベント

CAEPは、セキュリティ状態の変化を伝えるための具体的なイベントを定義しています。

**Table 4: Key CAEP Event Types and Use Cases**

| CAEP Event Type | Description | Example Trigger | Receiver Action |
| :--- | :--- | :--- | :--- |
| session-revoked | 特定のセッションを即時終了させる。 | 管理者がセッションを強制終了。ユーザーが他のデバイスでログアウト。 | 対応するセッションを即時無効化し、ユーザーに再認証を要求する。 |
| token-claims-change | セッションに関連するクレームが変更された。 | ユーザーの所属グループや役割が変更された。 | 新しいクレームに基づいて、アプリケーション内の権限を動的に更新する。 |
| credential-change | ユーザーの認証情報が変更された。 | ユーザーがパスワードを変更、またはMFAを登録/削除した。 | セキュリティポリシーに基づき、再認証やステップアップ認証を要求する。 |
| device-compliance-change | デバイスのセキュリティ状態が変化した。 | デバイスが企業のコンプライアンスポリシーに違反した（例: マルウェア感染）。 | 準拠していないデバイスからのアクセスをブロック、または制限する。 |
| assurance-level-change | 認証の保証レベルが変化した。 | ユーザーがより強力な認証方法（例: Passkey）で再認証した。 | より高い保証レベルを要求する機密リソースへのアクセスを許可する。 |

#### 4.2.3. Zero Trustとの連携

CAEPとSSFは、**Zero Trustアーキテクチャ**を実現するための核心的技術です。「決して信頼せず、常に検証する」というZero Trustの原則は、アクセス決定がリアルタイムのシグナルに基づいて行われることを要求します。

例えば、EDR（Endpoint Detection and Response）ツール（Transmitter）がデバイス上でマルウェアを検知した場合、device-compliance-changeイベントを発行します。このイベントストリームを購読しているAPIゲートウェイやアプリケーション（Receiver）は、たとえユーザーのアクセストークンが有効期限内であっても、そのセッションを**即座に**無効化できます。この継続的かつリアルタイムの評価と強制こそが、真のZero Trustの姿です。MicrosoftのCAE実装は、この信頼モデルに基づき、トークンの有効期間を24時間に延長し、失効を短い有効期限ではなくCAEPイベントに依存させることで、セキュリティとユーザビリティの両立を図っています。

このフレームワークは、これまでサイロ化されていたセキュリティツール群（EDR、IdP、DLPなど）を連携させる「神経系」として機能します。SSFという共通言語を通じて、各ツールが生成するリスクシグナルをリアルタイムで共有し、組織全体のセキュリティ体制を動的に、かつ協調的に制御することが可能になるのです。

### 4.3. パラダイムシフト: Decentralized Identity (DID) と Verifiable Credentials (VCs)

PasskeysやCAEPが既存のフェデレーションモデルを強化するものであるのに対し、**Decentralized Identity (DID)**と**Verifiable Credentials (VCs)**は、アイデンティティのあり方そのものを根本から変革するパラダイムシフトを提案します。

#### 4.3.1. 中核となるアイデア

その核心は、企業や政府といった中央集権的なプロバイダーが管理するアイデンティティモデルから、ユーザー自身がアイデンティティを所有し、管理する**自己主権型（Self-Sovereign）**モデルへの移行です。

*   **Decentralized Identifiers (DIDs):** ユーザーによって作成・管理され、いかなる中央機関にも依存しない、グローバルに一意で永続的な識別子です。これはユーザーのアイデンティティの「錨」となります。
*   **Verifiable Credentials (VCs):** 発行者（Issuer）が保有者（Holder、すなわちユーザー）に対して発行する、デジタルで改ざん検知可能な証明書です。ユーザーはこれを自身の**デジタルウォレット**に保管し、検証者（Verifier）に提示します。検証者は、元の発行者にリアルタイムで問い合わせることなく、VCの署名を暗号学的に検証し、その真正性を確認できます。

#### 4.3.2. 認証へのインパクト

従来の「ログイン」フローは、「提示」フローへと変化します。例えば、ユーザーが18歳以上であることを証明するために、政府のサイトにログインするのではなく、自身のウォレットから運転免許当局（Issuer）が発行した年齢証明のVCを提示します。この際、**選択的開示（Selective Disclosure）**や**ゼロ知識証明（Zero-Knowledge Proofs）**といった技術を用いることで、「18歳以上である: true」という事実のみを開示し、生年月日や住所といった他の個人情報を一切明かすことなく証明が可能です。

#### 4.3.3. 利点

このモデルは、ユーザーのプライバシーとデータコントロールを劇的に向上させます。また、攻撃者の標的となる巨大な個人情報データベース（ハニーポット）を削減し、繰り返し行われるKYC（本人確認）プロセスを効率化する可能性を秘めています。

これら3つのトレンド（Passkeys, CAEP, DIDs/VCs）は、互いに競合するものではなく、一つの大きな潮流の一部と見なすことができます。それは、静的でバイナリなパスワードベースのアクセス制御から、動的でリスク適応型、かつユーザー中心の**「オンデマンドの信頼（Trust-on-Demand）」**モデルへの移行です。Passkeysは認証時点での強力な信頼を確立し、CAEPはその信頼をセッション中にわたって継続的に評価し、DIDs/VCsはその信頼の根拠を中央集権的なプロバイダーからユーザー自身へと移譲します。アーキテクトにとって、この潮流は、パスワードレス認証への移行、イベントストリームを処理できるインフラの構築、そして中央集権的な属性ではなく検証可能なクレームを扱えるデータモデルの設計といった、未来を見据えたシステム設計の指針を示しています。

### 結論

本レポートでは、現代のプロダクトセキュリティにおける認証・認可レイヤーの核心的要素を、プロトコルの基本から実装上のベストプラクティス、潜在的リスク、そして未来のパラダイムに至るまで、包括的に分析した。

分析から導き出される結論は、アイデンティティとアクセスの管理が、静的なゲートキーピングから、動的でコンテキストを意識した、継続的な信頼評価のプロセスへと根本的に移行しているという事実である。

1.  **プロトコルの成熟とベストプラクティスの確立:** OAuth 2.0とOpenID Connectは、もはや単なる選択肢ではなく、セキュアなフェデレーションの必須基盤である。特に、**PKCE付き認可コードフロー**は、SPAやモバイルアプリを含むすべてのクライアントタイプにおけるデファクトスタンダードとして確立された。インプリシットフローのようなレガシーな手法からの脱却は、セキュリティ態勢を向上させる上で不可欠なステップである。
2.  **暗号学的選択のアーキテクチャへの従属:** JWT署名アルゴリズムの選択（HS256 vs. RS256）は、単なる性能のトレードオフではなく、システムの**信頼モデルとアーキテクチャ**に直結する戦略的決定である。マイクロサービスのような分散アーキテクチャの普及は、秘密鍵を単一のサービスに隔離できる**RS256**を、論理的かつ安全な選択肢として決定づけた。
3.  **脆弱性から脅威インテリジェンスへの転換:** **リフレッシュトークン・ローテーション**のような高度なメカニズムは、単に脆弱性を緩和するだけでなく、トークン盗難という受動的なリスクを、**能動的に検知可能なセキュリティイベント**へと転換させる。これは、インシデントレスポンスを事後対応からプロアクティブな防御へと進化させる、強力なパラダイムシフトである。
4.  **未来への潮流とZero Trustの具現化:** **Passkeys**、**Shared Signals Framework (CAEP)**、そして**Decentralized Identity (DID/VC)**は、それぞれが独立したトレンドではなく、相互に補完し合いながら「オンデマンドの信頼」という未来像を形成している。Passkeysはフィッシング耐性のある強力な認証を提供し、CAEPはその信頼をリアルタイムで継続的に評価し、DID/VCは信頼の源泉をユーザー自身に回帰させる。特にSSF/CAEPは、これまでサイロ化されていたセキュリティシグナルを連携させる「神経系」として機能し、真のZero Trustアーキテクチャを実現するための不可欠な要素となるであろう。

プロダクトセキュリティエンジニアおよびアーキテクトは、これらの原則とトレンドを深く理解し、自社のシステム設計に反映させることが求められる。それは、単に個別の脆弱性を修正することに留まらず、変化し続ける脅威ランドスケープと技術的パラダイムに適応し、将来にわたって堅牢かつスケーラブルな信頼の基盤を構築するための、戦略的責務である。
