---
tags:
  - langchain
  - operations
  - mloops
  - production
  - security
  - resilience
---
# 運用：本番運用に関する考慮事項

LLMアプリケーションをプロトタイプから堅牢な本番システムへと移行させるには、コードの機能性だけでなく、環境、回復力、セキュリティといった、より広い運用上の課題に対処する必要があります。

## 1. 環境戦略：ローカルLLM vs クラウドAPI

LLMとエンベディングモデルの選択は、技術的な性能だけでなく、ビジネス要件にも大きく影響される戦略的な決定です。

| 特徴 | クラウドAPI (例: OpenAI) | ローカルLLM (例: Ollama + HuggingFace) |
| :---- | :---- | :---- |
| **性能** | GPT-4oのような最先端モデルにアクセス可能。最高の性能が期待できる。 | Llama 3のような強力なオープンソースモデルを利用可能。多くのタスクで商用モデルに匹敵するが、最先端には一歩譲る場合がある。 |
| **コストモデル** | 従量課金制（トークンあたり）。利用量に応じて変動し、予測が難しい場合がある。 | 無料（初期のハードウェア投資を除く）。運用コストは固定的で予測可能。 |
| **データプライバシー** | データは外部のサーバーに送信される。法務やセキュリティ部門の厳しい審査が必要になる可能性がある。 | 全てのデータは組織のネットワーク内で完結する。最高のデータプライバシーと主権を確保できる。 |
| **セットアップと保守** | 容易。APIキーの設定のみで利用可能。インフラの保守は不要。 | 中程度。ライブラリのインストール、モデルのダウンロード、GPU環境の管理など、自前でのインフラ保守が必要。 |
| **カスタマイズ性** | 不可。提供されたモデルをそのまま利用する。 | 可能。特定のドメインデータに合わせてモデルをファインチューニングできる可能性がある。 |
| **理想的な用途** | 最高の性能を迅速に導入したい場合。データプライバシー要件がクリアできるプロトタイプやアプリケーション。 | データプライバシーが最優先事項の場合。コストを厳密に管理したい場合。オンプレミス環境での運用。 |

LangChainの利点は、両方のアプローチに対して共通の`Runnable`インターフェースを提供している点です。これにより、アプリケーションのコアロジックを書き直すことなく、ビジネス要件や技術検証の結果に応じて、クラウドAPIとローカルLLMを比較的容易に切り替えることが可能です。

## 2. システムの回復力（Resilience）

エージェントは非決定的な性質を持つため、予期せぬエラーや不適切な応答を生成する可能性があります。本番システムでは、これらの問題に優雅に対処し、システム全体が停止することを防ぐための多層的な防御戦略が必要です。

### 2.1. ツールレベルのエラー処理

カスタムツールは、外部APIの呼び出しやライブラリの利用など、失敗する可能性のある処理を含むことがよくあります。ツール内で`try...except`ブロックを使用し、これらの例外を捕捉することが不可欠です。

**悪い例（エージェントをクラッシュさせる可能性）**:
```python
@tool
def call_external_api(query: str) -> str:
    # ネットワークエラーやAPIのレート制限で例外が発生する可能性がある
    return requests.get(f"https://api.example.com?q={query}").json()
```

**良い例（エラーを捕捉し、エージェントに情報を返す）**:
```python
@tool
def call_external_api(query: str) -> str:
    """外部APIを呼び出して情報を取得します。"""
    try:
        response = requests.get(f"https://api.example.com?q={query}")
        response.raise_for_status() # HTTPエラーがあれば例外を発生させる
        return response.json()
    except requests.RequestException as e:
        # エージェントが自己修正に利用できるような、役立つエラーメッセージを返す
        return f"API呼び出し中にネットワークエラーが発生しました: {e}"
```
このように、ツールが失敗した場合でも、その失敗情報を`Observation`としてエージェントに返すことで、エージェントは「別のツールを試す」「クエリを変えて再試行する」といった自己修正の機会を得ることができます。

### 2.2. Executorレベルのエラー処理

`AgentExecutor`には、LLMの出力が不正でアクションに解析できない場合に、エージェントがクラッシュするのを防ぐためのパラメータが用意されています。

*   `handle_parsing_errors=True`: このパラメータを設定すると、解析エラーが発生した場合に、そのエラーメッセージをエージェントの`Observation`としてフィードバックし、処理を継続させることができます。プロンプトに「もし解析エラーが出たら、出力形式を修正してもう一度試してください」といった指示を加えておくことで、エージェントは自己修正を試みることができます。

### 2.3. プロンプトレベルのガードレール

プロンプトは、エージェントの行動を制約し、望ましくない結果を防ぐための最も重要な「ガードレール」です。

*   **スコープの限定**: 「提供されたコンテキストの情報**のみ**に基づいて回答してください。」
*   **安全な出口の提供**: 「コンテキストに答えが記載されていない場合は、決して推測で回答せず、「提供された情報からは分かりません」と明確に回答してください。」
*   **不確実性への対処**: 「決定的な答えが見つからない場合は、推測するのではなく、情報が入手不可能であると述べなさい。」

これらの指示をプロンプトに含めることで、ハルシネーションを抑制し、エージェントの応答の信頼性を高めることができます。

## 3. セキュリティと信頼性：高度なプロンプト技術

エンタープライズ向けのRAGシステムでは、特に情報漏洩や不適切な応答を防ぐための、より高度なプロンプトガードレール技術が求められます。

*   **クエリの分類**: ユーザーの質問をまず分類し、その意図を判断します。「社内規定に関する質問」「雑談」「不適切な質問」などを分類し、質問の種類に応じて異なるプロンプトやRAGパイプラインを適用します。
*   **知識領域の制限**: ユーザーの役割や権限に応じて、アクセスできる知識の範囲を動的に制限します。例えば、人事部のユーザーにしか財務関連のドキュメントへのアクセスを許可しない、といった制御をRAGパイプラインの前段に組み込みます。
*   **応答の検証**: LLMが生成した回答を、公開する前にもう一度別のLLMコールで検証する、といった多段チェックの仕組みを導入します。例えば、「この回答は、個人情報や機密情報を含んでいませんか？」といったチェックを行うLLMエージェントを配置します。

これらの運用上の考慮事項に事前に対処することで、LLMアプリケーションは単なる技術デモから、ビジネス要件を満たす信頼性の高い本番システムへと進化します。
