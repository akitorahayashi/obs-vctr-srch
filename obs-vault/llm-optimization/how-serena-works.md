---
tags:
  - llm
  - optimization
  - ai
  - mcp
  - serena
  - gemini
---

# Serenaの仕組みとGeminiCLIの連携ガイド

## はじめに：現代的AIコーディングスタックの解明

本レポートは、AIを活用したコーディング支援ツール「Serena」が特定のLLM（大規模言語モデル）クライアントに限定されるものなのか、そしてGoogleの「Gemini CLI」と連携できるのか、という問いに明確な答えを提示します。結論から述べると、SerenaはClaude Code専用ではなく、Gemini CLIと強力に連携させることが可能です。このレポートは、その連携を実現するための決定版ガイドとして、技術的な背景から具体的な実装手順、さらには戦略的な活用法までを網羅的に解説します。

まず、極めて重要な点として、本稿で扱う「Serena」についての明確化から始めます。現在、「Serena」という名称を持つ技術が二種類存在し、混同を招きやすいためです。本レポートが対象とするのは、\*\*oraios/serena\*\*として知られる、最新のオープンソースAIコーディングエージェントツールキットです。これは、LLMに高度なコード解析・編集能力を付与するために設計された現代的なツールです。

一方で、これとは全く無関係の、Serena Software Inc.（現在はMicro Focus社の一部）が開発したレガシーなエンタープライズ向けソフトウェア群が存在します。これにはPVCS Version ManagerやDimensions CMといった構成管理ツールが含まれます。ユーザーが誤ったドキュメントを参照することを避けるため、本レポートでは

oraios/serenaにのみ焦点を当てます。

このoraios/serenaとGemini CLIの連携を可能にする核心技術が、\*\*モデルコンテキストプロトコル（Model Context Protocol, MCP）\*\*です。MCPは、Gemini CLIのようなAI「クライアント」と、Serenaのような専門的な「ツールサーバー」を分離し、両者間の標準化された通信を可能にする規約です。このアーキテクチャこそが、AIアシスタントをよりモジュール化し、強力にする新しい時代の幕開けを象徴しています。

## 第1章 コアコンポーネントの深掘り

この先進的なワークフローを理解するためには、まず二つの主要なコンポーネント、SerenaとGemini CLIの役割と特性を正確に把握する必要があります。

### 1.1 Serena (oraios/serena): コードベースのセマンティックエンジン

Serena (oraios/serena)は、LLMをローカルのコードベース上で直接動作する本格的なコーディングエージェントへと変貌させる、無料のオープンソースMCPサーバーです。その最大の特徴は、単なるテキスト処理ツールではない点にあります。

#### 1.1.1 セマンティックな優位性

Serenaのアーキテクチャは、広く実装されている\*\*言語サーバープロトコル（Language Server Protocol, LSP）\*\*を基盤としています。LSPは、Visual Studio CodeやIntelliJといった最新の統合開発環境（IDE）が、コードの補完、定義へのジャンプ、リファレンスの検索といった高度な機能を実現するために使用している技術です。SerenaはこのLSPの能力をLLMに提供します。

このLSPの活用が、Serenaの決定的な差別化要因です。多くのAIコーディングツールが、単純なテキスト検索（grepなど）や、時には不正確な結果を返すことがあるベクトル検索に依存しているのに対し、Serenaはコードを単なる文字列としてではなく、シンボル、関数、クラス、そしてそれらの間の依存関係といった構造化されたエンティティとして「理解」します。

このセマンティック（意味的）な理解により、LLMは「calculate\_totalという関数の定義はどこか？」「このクラスを参照しているすべての場所をリストアップせよ」といった、開発者がIDEで行うような高レベルな問いに、極めて正確かつ効率的に答えることができます。結果として、LLMがコードベースを理解するために必要なコンテキスト（トークン）の量が劇的に削減され、応答速度の向上とコスト削減、そして生成されるコードの品質向上に直結します。

#### 1.1.2 主要な機能

Serenaは、このセマンティックな理解を土台に、以下のような強力な機能群を提供します。

* **セマンティックなコード検索**: シンボル名や型に基づいて、コード内のエンティティを正確に検索します。
* **シンボルレベルの精密な編集**: ファイル全体を書き換えるのではなく、特定の関数やクラスの本体だけをピンポイントで置換・挿入します。
* **シェルコマンドの実行**: テストの実行や依存関係のインストールなど、開発環境と直接対話するタスクを自動化します。
* **永続的なメモリシステム**: プロジェクト固有の情報を.serena/memories/ディレクトリに記憶し、セッションをまたいでコンテキストを維持します。

### 1.2 Gemini CLI: ターミナルに常駐するGoogleのAIエージェント

Gemini CLIは、Googleの強力なGeminiモデルファミリーへターミナルから直接アクセスできるようにする、オープンソースのコマンドラインAIエージェントです。単なる対話ツールにとどまらず、開発者の生産性を飛躍させるための様々な機能を備えています。

このツールがSerenaとの連携において決定的に重要なのは、その設計思想の核に**モデルコンテキストプロトコル（MCP）のネイティブサポート**が組み込まれている点です。これは後付けの機能ではなく、Gemini CLIが外部のツールサーバーと接続し、その能力を拡張するための基本的な仕組みとして用意されています。これにより、Gemini CLIはSerenaが提供する専門的なコーディングツール群をシームレスに利用できるのです。

また、Gemini CLIはコーディングに特化しているだけでなく、コンテンツ生成や問題解決、リサーチといった幅広いタスクに対応する汎用的なローカルユーティリティとしても機能します。さらに、VS Codeの拡張機能であるGemini Code Assistのエージェントモードは、このGemini CLIを内部的に利用しており、両者は技術を共有する関係にあります。

## 第2章 見えざる握手：モデルコンテキストプロトコル（MCP）の理解

SerenaとGemini CLIという、本来は独立した二つのツールがなぜ連携できるのか。その答えは、両者が共通言語として話す「モデルコンテキストプロトコル（MCP）」にあります。

MCPは、AIアシスタントのアーキテクチャにおける重要な抽象化レイヤーです。これは、「MCPクライアント」（LLMとの対話インターフェース。例：Gemini CLI, Claude Code）が、「MCPサーバー」（専門的なツールを提供するコンポーネント。例：Serena）によって提供されるツール群を動的に発見し、実行するための標準化された仕様と定義されます。

このプロトコルの存在がもたらす影響は計り知れません。MCPは、AIアシスタントの世界にモジュール性とオープンなエコシステムをもたらします。従来、LLMとその利用ツールは、単一のベンダーによって密結合されたモノリシックなシステムとして提供されることが多くありました。しかしMCPは、この依存関係を断ち切ります。

このアーキテクチャの採用は、技術戦略における重要な転換点を意味します。ユーザーは、特定のLLMベンダーに縛られることなく、自分の好むLLMクライアント（Gemini）と、最も強力で専門的なツールサーバー（Serena）を自由に組み合わせる「ベスト・オブ・ブリード」なAIアシスタントを構築できるようになります。これにより、開発者は最大限の柔軟性を手に入れ、ベンダーロックインのリスクを回避し、コミュニティ主導のツール開発イノベーションの恩恵を享受することが可能になるのです。MCPは、AIアシスタントの未来が、閉じたシステムから相互運用可能なオープンなエコシステムへと向かうことを示唆しています。

## 第3章 決定版連携ガイド：SerenaとGemini CLIの接続

ここでは、SerenaとGemini CLIを連携させるための、実践的かつ詳細な手順を解説します。

### 3.1 環境準備と前提条件

連携を実現するには、まず二つのツールをインストールする必要があります。

#### 3.1.1 Gemini CLIのインストール

Gemini CLIは、npm（Node.jsパッケージマネージャ）またはHomebrew（macOS用）を使用してインストールできます。

* **npmを使用する場合（Node.js v20以上が必要）**:  
  Bash  
  npm install \-g @google/gemini-cli

* **Homebrewを使用する場合（macOS）**:  
  Bash  
  brew install gemini-cli

インストール後、geminiコマンドを実行し、画面の指示に従ってGoogleアカウントで認証を完了させてください。

#### 3.1.2 uvのインストール

Serenaの実行には、高速なPythonパッケージインストーラ兼ランナーであるuvの使用が推奨されています。

* **macOSの場合**:  
  Bash  
  brew install uv

* **Linuxの場合**:  
  Bash  
  sudo apt update  
  sudo apt install pipx  
  pipx ensurepath  
  pipx install uv

uvをインストールすることで、Serenaを仮想環境内に素早く展開・実行できるようになります。

### 3.2 核心となる接続設定：\~/.gemini/settings.jsonの編集

次に、Gemini CLIにSerenaをMCPサーバーとして認識させるための設定を行います。ホームディレクトリ内の.geminiフォルダにあるsettings.jsonファイルを開き（なければ作成します）、以下のmcpServersブロックを追加または編集します。

JSON

{  
  "selectedAuthType": "gemini-api-key",  
  "theme": "Default",  
  "checkpointing": true,  
  "mcpServers": {  
    "serena": {  
      "command": "uvx",  
      "args":  
    }  
  }  
}

#### 3.2.1 設定ブロックの解説

このJSONブロックの各パラメータは、以下の意味を持ちます。

* "serena":: Gemini CLI内でこのMCPサーバーを識別するための任意の名前です。  
* "command": "uvx": サーバーを起動するために実行するコマンドを指定します。  
* "args": \[...\]: uvxコマンドに渡す引数のリストです。  
  * "--from", "git+https://github.com/oraios/serena": uvxに対して、SerenaをGitHubリポジトリから直接取得して実行するよう指示します。これにより、常に最新バージョンが利用されます。
  * "serena-mcp-server": 実行するSerenaのスクリプト名を指定します。  
  * "--context", "ide-assistant": Serenaの動作コンテキストを、IDEのような対話的なアシスタント作業に最適化するよう設定します。他にもagentなどのコンテキストが存在します。
  * "--enable-web-dashboard", "false": Serena起動時にWebダッシュボードがブラウザで自動的に開くのを無効にします。CLI中心のワークフローではこの設定が望ましいです。この設定は、ログの表示に関する一般的な疑問にも答えるものです。
  * "--project", "${PWD}": これは極めて重要なパラメータです。PWD（Print Working Directory）という環境変数を使い、Gemini CLIを起動した現在のディレクトリのパスをSerenaに渡します。これにより、Serenaは対象となるプロジェクトを自動で認識します。

### 3.3 起動、検証、そして最初の対話

設定が完了したら、実際に連携が機能するかを確認します。

1. **起動**: ターミナルで、作業対象のプロジェクトのルートディレクトリに移動します。  
2. **実行**: geminiコマンドを実行して、Gemini CLIを起動します。  
3. **検証**: Gemini CLIのプロンプト内で、/mcpと入力してEnterキーを押します。

設定が正しければ、以下のような出力が表示され、SerenaがMCPサーバーとして正常に認識され、利用可能なツール群がリストアップされていることを確認できます。

\> /mcp  
  🟢 serena \- Ready (23 tools)  
    \- list\_dir  
    \- find\_file  
    \- replace\_regex  
   ... (その他のツール)

この表示が確認できれば、SerenaとGemini CLIの連携は成功です。

## 第4章 統合ワークフローの習熟：実践的な利用法とベストプラクティス

連携が成功したところで、次はこの強力な環境を最大限に活用するための具体的なワークフローとベストプラクティスを学びます。

### 4.1 オンボーディングという儀式：コードベースの「認知マップ」構築

Serenaを効果的に利用するための最初の、そして最も重要なステップは「オンボーディング」です。これは単なるコマンド実行ではなく、Serenaが対象プロジェクトの「認知マップ」を構築するための儀式と捉えるべきです。

ユーザーがonboardingコマンドを実行すると、SerenaはLSPを利用してプロジェクト全体のコードを解析し、すべてのファイル構造、クラス、関数、変数といったシンボルとその関係性をインデックス化します。このセマンティックな情報は、プロジェクトルートに作成される.serena/ディレクトリ内に「記憶」として保存されます。

このプロセスがなぜ重要かというと、この「認知マップ」がLLMの外部記憶として機能するからです。LLMは、プロジェクトの全ファイルを自身のコンテキストウィンドウに読み込むことなく、このコンパクトで構造化されたインデックスに問い合わせることで、巨大で複雑なコードベースの全体像を効率的に把握できます。これは、AIの能力を最大限に引き出すための高度なコンテキストエンジニアリングの一形態と言えます。

### 4.2 対話の二重性：自然言語による指示と直接的なツール呼び出し

Serenaと連携したGemini CLIとの対話には、二つの主要なスタイルがあります。

#### 4.2.1 自然言語による委任

一つは、高レベルで会話的な指示を与える方法です。例えば、以下のようにプロンプトを入力します。  
「このディレクトリでserenaをactivateしてから、onboardingして」 14

このモードでは、GeminiのLLMがユーザーの意図を解釈し、適切なSerenaのツール（この場合はactivate\_projectとonboarding）を自律的に選択し、順番に実行します。

#### 4.2.2 指示による外科的な精度

もう一つは、より高度で確定的な制御を可能にする、ツールの直接呼び出しです。@(サーバー名).(ツール名) \[引数\]という構文を使用します。

* @serena.activate\_project  
* @serena.onboarding

この方法は、LLMの解釈を介さずに特定のツールを確実に実行したい場合や、スクリプト化したい場合に非常に有効です。

#### 表1：Gemini CLIユーザーのための必須Serenaツール

以下の表は、/mcpコマンドでリストされるツール群の中から、特に利用頻度が高く強力なものを抜粋し、その目的と使用例をまとめたものです。これは、ユーザーが自身の意図を具体的なツール実行に結びつけるためのクイックリファレンスとして機能します。

| ツール名 (@serena.\<tool\_name\>) | 目的 | Gemini CLIプロンプト例 |
| :---- | :---- | :---- |
| activate\_project | カレントディレクトリのプロジェクトに対してSerenaを有効化する。最初のステップ。 | @serena.activate\_project |
| onboarding | コードベース全体を解析し、セマンティックマップ（インデックス）を構築する。 | このプロジェクトの全体像を把握するためにonboardingを実行して。 または @serena.onboarding |
| get\_symbols\_overview | ファイル内の主要なシンボル（クラス、関数など）の概要をリストアップする。 | main.pyの主要な関数とクラスをリストアップして。 |
| find\_symbol | 特定のシンボル（例：関数）の定義箇所を検索する。 | 「calculate\_price」という関数の定義を見つけて。 |
| find\_referencing\_symbols | 特定のシンボルがコード内のどこで呼び出されているか（参照されているか）をすべて検索する。 | 「User」クラスがどこで使われているか全部教えて。 |
| replace\_symbol\_body | 関数やメソッドの内部コードをピンポイントで置換する。 | @serena.replace\_symbol\_body \--symbol\_name utils.calculate\_price \--new\_body "return price \* 1.1" |
| search\_for\_pattern | 正規表現を使い、プロジェクト全体を対象にテキスト検索を行う。 | プロジェクト全体で "TODO:" というコメントを検索して。 |
| execute\_shell\_command | シェルコマンドを実行する（例：テスト実行、依存関係インストール）。 | npm installを実行して、その後テストを実行してください。 |

### 4.3 コードベースの同期：再オンボーディングの重要性

重要なベストプラクティスとして、Serenaが作成した.serena/ディレクトリ内のインデックスは、コードの変更に応じて**自動的には更新されない**という点を覚えておく必要があります。新しいファイルを追加したり、大規模なリファクタリングを行ったりした後は、@serena.onboardingを再度手動で実行し、セマンティックマップを最新の状態に更新する必要があります。これを怠ると、AIの分析精度が低下する可能性があるため、このメンテナンス作業は継続的な精度の確保に不可欠です。

## 第5章 戦略的洞察と比較分析

### 5.1 Gemini CLI 対 Claude Code：Serenaユーザーの体験

Serenaの能力を最初に広く知らしめたのは、Anthropic社のClaude Codeでした。一方で、Gemini CLIはGoogleによる「高速な追随製品」と評されることもあります。両クライアントは同じMCPプロトコルを通じてSerenaに接続しますが、ユーザー体験は基盤となるLLM（Gemini対Claude）の推論能力によって異なる可能性があります。

例えば、あるモデルは複雑な複数ステップのタスクを粘り強く自律的に解決しようとするのに対し、別のモデルは途中で諦めて手動でのツール使用を促す傾向があるかもしれません。どちらのクライアントが特定のタスクにおいてSerenaのツールをより巧みに、あるいはより意図通りに使いこなすかは、今後のコミュニティからのフィードバックや継続的な評価によって明らかになっていくでしょう。

### 5.2 外部ツールサーバーという戦略的価値

本レポートで解説したアーキテクチャは、単なる技術的な好奇心を満たすものではなく、プロの開発者にとって明確な戦略的価値を提供します。

* **コスト削減と効率性**: Serenaのセマンティックなアプローチは、LLMに与えるべきコンテキストのトークン量を削減し、API利用コストの直接的な節約と応答時間の短縮を実現します。
* **ベンダーロックインの回避**: オープンソースのツールサーバー（Serena）と標準プロトコル（MCP）を利用することで、開発者は使い慣れた専門的なツール環境を維持したまま、将来登場するであろう新しいLLMクライアントへ自由に乗り換えることができます。
* **卓越した能力**: Serenaは、LLM単体では持ち得ないIDEレベルのコードインテリジェンスを提供します。これにより、AIは本来なら扱いきれないような大規模で現実的なコードベースにおいても、効果的に作業を進めることが可能になります。
* **カスタマイズと制御**: Serenaの動作モード（planning, editingなど）やコンテキスト 10 から、Gemini CLIのプロンプト設定に至るまで、スタック全体がオープンで設定可能です。これにより、開発者は自身のワークフローに最適化された環境を構築できます。

## 結論：独自のAI開発環境の構築

本レポートの分析を通じて、以下の結論が導き出されました。  
Serena (oraios/serena) は、特定のLLMに依存しない強力なツールサーバーであり、その能力の核心はLSPを通じたコードのセマンティックな理解にあります。モデルコンテキストプロトコル（MCP）という標準化された架け橋を介してGemini CLIと連携させることで、開発者は極めて強力かつオープンで、高度にカスタマイズ可能なAIコーディングアシスタントを手に入れることができます。  
この先進的な環境を最大限に活用するための最終的な推奨事項は以下の通りです。

1. **モジュラーアプローチの採用**: モノリシックなツールに固執せず、最高のコンポーネントを組み合わせるという考え方を取り入れること。  
2. **対話スタイルの習熟**: 自然言語による大まかな指示と、直接的なツール呼び出しによる精密な操作の両方を使い分け、タスクに応じて最適なアプローチを選択すること。  
3. **オンボーディングの習慣化**: コードベースに大きな変更を加えた後には、必ず@serena.onboardingを再実行する習慣を身につけ、AIの「認知マップ」を常に最新の状態に保つこと。

今後の開発動向、問題報告、そしてコミュニティとの議論については、oraios/serenaの公式GitHubリポジトリが最も信頼できる情報源となります。このガイドが、次世代のAI開発環境を構築する一助となれば幸いです。
