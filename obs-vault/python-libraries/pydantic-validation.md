---
tags:
  - python
  - pydantic
  - data-validation
  - serialization
  - settings-management
  - fastapi
  - dataclasses
  - api
---

# Pydantic実践分析：基本理念から体系的統合まで

---

## 1.0 コアコンセプト：第一級市民としてのデータ

Pydanticのコアコンセプトは、Python開発におけるデータ構造を第一級市民へと昇格させることにあります。その中心的な思想は、データの形状と制約に関する単一の宣言的な真実の源（a single source of truth）を作成することです。これにより、Pythonの型ヒントを活用して実行時のデータバリデーション、パース、シリアライゼーションを行い、データ境界における曖昧さと信頼性の欠如という問題を解決します。このアプローチは、実行時エラーを明確で対処可能なValidationError例外へと変換します。

Pydanticの設計は、「検証するな、パースせよ（Parse, Don't Validate）」という原則の具現化です。アプリケーション全体に多数の防御的なチェック（例：if isinstance()）を記述する代わりに、Pydanticはデータがモデルにインスタンス化された時点で、その構造と型が定義されたスキーマに準拠することを保証します。これにより、バリデーションの責務はアプリケーションの境界にシフトされ、コアとなるビジネスロジックは信頼できる、よく構造化されたオブジェクトを操作することに集中できます。公式ドキュメントにある「Pydanticは入力データではなく、出力の型と制約を保証する」という記述は、この哲学を最も的確に表現しています。Pydanticは単なるチェッカーではなく、コンストラクタであり、型強制者なのです。これは、単純なバリデーションライブラリとの根本的な違いです。

このライブラリのアーキテクチャ基盤として、コアとなるバリデーションロジックはRustで実装されたpydantic-coreによって提供されており、純粋なPython実装と比較して大幅なパフォーマンス向上を実現しています。この高性能なコアにより、PydanticはWeb APIのような高スループットなアプリケーションにも適した選択肢となっています。

---

## 2.0 アーキテクチャパターンと設計思想

本セクションでは、Pydanticが果たす主要なアーキテクチャ上の役割を分析し、各アプリケーションの背後にある設計思想を考察し、代替技術との比較を行います。

### 2.1 パターン：サービス指向アーキテクチャにおけるAPI境界の強制

#### コンテキストと目的

マイクロサービスやREST APIなどの現代的なアーキテクチャにおいて、最も重大な障害点は、サービスが外部の信頼できないデータを受け取る境界です。Pydanticは、APIリクエストボディとレスポンスペイロードの明示的なスキーマを定義するために、この境界で広く使用されています。[[fastapi-evaluation-report|FastAPI]]のようなフレームワークは、この能力を直接基盤として構築されており、Pydanticモデルを使用して受信JSONの処理、バリデーション、そしてOpenAPIドキュメントの自動生成を行っています。Pydanticと[[fastapi-evaluation-report|FastAPI]]の緊密な統合は、Pydanticが単なるライブラリ以上のものであることを示しています。それは、データモデルがAPIコントラクト、バリデーション、ドキュメンテーションを同時に駆動するという、API開発における新しいパラダイムの実現者なのです。

#### 設計思想：腐敗防止層と明示的コントラクト

APIエンドポイントにおけるPydanticモデルは、腐敗防止層（Anti-Corruption Layer）として機能します。これは、煩雑で信頼性の低い外部データを、クリーンで検証済み、かつドメイン固有の内部表現に変換します。これにより、サービスの内部ロジックが外部クライアントの変動から切り離されます。モデルは実行可能なコントラクトとして機能し、データがシステムに入った瞬間からその整合性を保証します。

#### 比較分析

* **vs. Marshmallow:** Marshmallowはシリアライゼーション／デシリアライゼーションに焦点を当てた成熟したライブラリです。現代のプロジェクトでは、より宣言的で型ヒントネイティブな構文を持つPydanticが好まれる傾向にあります。これは、より「Pythonic」に感じられ、定型的なコードを削減するためです。Marshmallowは高い柔軟性を提供しますが、冗長になる可能性があります。Pydanticのバリデーションとデータ構造定義を単一のクラスに緊密に結合させるアプローチは、人間工学的な観点から大きな利点です。
* **vs. [[../django/index_django.md|Django]] REST Framework (DRF) Serializers:** DRF Serializerは[[../django/index_django.md|Django]]エコシステム、そしてしばしば[[../django/index_django.md|Django]]モデルと密結合しています。Pydanticはフレームワークに依存しないソリューションを提供します。このギャップを埋めるために、drf-pydanticやdjango-ninjaといったライブラリが登場しました。これらはDRF SerializerをPydanticモデルに置き換えることで、パフォーマンス（Pydantic V2のRustコア対純粋PythonのDRF）と、よりモダンな型ヒント駆動のワークフローを実現します。

### 2.2 パターン：デプロイ可能システムのための型安全な設定管理

#### コンテキストと目的

開発、テスト、本番といった多様な環境にわたるアプリケーション設定の管理は、エラーの一般的な原因です。PydanticのBaseSettingsは、設定を型ヒント付きのクラスとして定義し、環境変数、.envファイル、シークレットストアから自動的に値を読み込むための堅牢なパターンを提供します。この機能は現在、pydantic-settingsという独立したパッケージで提供されています。

#### 設計思想：宣言的かつ不変な設定

このパターンは、設定を単なる変数の集合としてではなく、構造化され、検証されたオブジェクトとして扱います。型（例：int, HttpUrl）を定義することで、設定が無効な場合（例：不正な形式のデータベースURL）に、実行時に予測不能な失敗をするのではなく、起動時に即座に失敗（fail fast）させることができます。結果として得られる設定オブジェクトは通常、不変（immutable）として扱われ、実行時の設定変更を防ぎます。BaseSettingsの哲学は、設定のための単一の検証済み真実の源を作成することにあり、その値の優先順位（イニシャライザ > 環境変数 > .envファイル > シークレット > デフォルト値）は、運用上の重要な知識です。

#### 比較分析

* **vs. 従来手法 (os.environ, configparser, PyYAML):** 標準的なアプローチでは、手動でのパース、型キャスト（例：int(os.environ.get(...))）、およびバリデーションロジックが必要です。これはエラーが発生しやすく、冗長です。BaseSettingsはこれらすべてを自動化し、型安全性、バリデーション（URLやメールアドレスなど）、そして明確なエラーメッセージを標準で提供します。これにより、設定ロジックは自己文書化された単一のクラスに集約されます。

### 2.3 パターン：疎結合な内部サービスのためのデータ転送オブジェクト（DTO）

#### コンテキストと目的

単一のアプリケーション内やマイクロサービス間では、レイヤー間（例：サービスレイヤーからデータアクセスオブジェクトへ）やプロセス間でデータを渡す必要があります。この目的で生の辞書を使用するのは脆弱です。Pydanticモデルは、このデータの明確で不変な構造を定義する理想的なデータ転送オブジェクト（DTO）として機能します。これにより、コンポーネント間で渡されるデータが厳格なコントラクトに準拠することが保証されます。DTOの核心的な目的は、レイヤーを疎結合にし、過剰なデータ送信（over-posting）の脆弱性を回避し、基盤となるデータベーススキーマやプレゼンテーション層の特定のニーズから独立した、データ交換のための安定したコントラクトを作成することです。

#### 設計思想：暗黙的より明示的

Pythonの禅（The Zen of Python）にある「暗黙的より明示的（Explicit is better than implicit）」が、ここでの指導原則です。Pydantic DTOはデータの形状を明示的にします。これにより、コードの可読性が向上し、リファクタリングがより安全になり（静的型チェッカーが不一致を検出できる）、辞書キーのタイプミスや予期せぬNone値に関連するバグのクラス全体を排除します。

#### 比較分析

* **vs. dataclasses:** dataclassesは、定型的なコードが少ない単純なデータ保持クラスを作成するのに優れています。しかし、実行時のバリデーションや型強制は提供しません。データが信頼できないソースから来る場合や、単純な型ヒントを超える複雑なバリデーションルールが必要な場合には、Pydanticを選択すべきです。純粋に内部の、信頼できるデータ転送には、dataclassesがより軽量な代替手段となり得ます。
* **vs. attrs:** attrsはdataclassesよりも強力で成熟したライブラリであり、バリデーターやコンバーターなどの機能を提供します。哲学的な主な違いは、attrsがバリデーションに対して「オプトイン」であるのに対し、Pydanticは「オプトアウト」である点です。attrsとcattrsを組み合わせることで、より柔軟でコンポーネントベースのアプローチが可能になり、一部のベンチマークでは高速になることがあります。しかし、より多くの設定が必要です。Pydanticの「全部入り（batteries-included）」アプローチは、バリデーション、型強制、シリアライゼーションを一つの統合された、意見の強い（opinionated）パッケージで提供し、特にAPI向けのDTOにとっては、しばしばより便利です。

#### 表1：Pythonデータハンドリングライブラリの比較分析

| 特徴 | Pydantic | attrs (+cattrs) | dataclasses (標準ライブラリ) | Marshmallow |
| :---- | :---- | :---- | :---- | :---- |
| **主な用途** | 境界でのデータバリデーション、パース、設定管理。 | クラスの定型コード削減、柔軟なデータ構造化。 | 軽量な内部データコンテナ（DTO）。 | 複雑なオブジェクトのシリアライズ／デシリアライズ（マーシャリング）。 |
| **バリデーション哲学** | **オプトアウト:** バリデーションと型強制がデフォルトで有効。 | **オプトイン:** バリデーターを明示的に定義し、アタッチする。 | 組込みなし（__post_init__が必要）。 | スキーマベースのバリデーション。データオブジェクトとは分離。 |
| **パフォーマンス** | 非常に高速（Rustコア）。ただしデフォルトのバリデーション／型強制によるオーバーヘッドあり。 | 一般的にインスタンス化が高速。cattrsは高度に最適化されている。 | 最速のインスタンス化（最小限のオーバーヘッド）。 | 純粋Python。一般的にPydantic V2やcattrsより遅い。 |
| **型強制** | デフォルトで積極的かつ自動的（例：'1' -> 1）。 | コンバーターを介したオプトイン。 | なし。 | スキーマフィールドで明示的に定義。 |
| **可変性** | デフォルトで可変。不変にも設定可能。 | デフォルトで可変。frozen=Trueで容易に不変に設定可能。 | デフォルトで可変。frozen=Trueで容易に不変に設定可能。 | スキーマはデータを操作するものであり、オブジェクトの可変性は制御しない。 |
| **エコシステムと統合** | [[fastapi-evaluation-report|FastAPI]]、LangChainなどの基盤。強力なモダンエコシステム。 | 成熟し、高い評価を得ている。dataclassesの基礎。 | 標準ライブラリの一部（依存関係なし）。 | 成熟しており、Flaskや[[../django/index_django.md|Django]]などのフレームワーク用の多くのプラグインが存在。 |
| **エラー報告** | 非常に詳細で構造化された、コンテキスト付きのValidationError。 | デフォルトでは詳細度が低い。「ハッピーパス」に最適化されている。 | N/A。 | 良好なエラー報告。カスタマイズ可能。 |

### 2.4 パターン：多段階処理パイプラインにおけるデータ整合性

#### コンテキストと目的

データエンジニアリングやETL/ELTワークフローでは、データは取り込み、クリーニング、変換、ロードという複数のステージを流れます。各ステップでデータ品質とスキーマの一貫性を維持することが最も重要です。Pydanticモデルは、各ステージ間の境界を越える際にデータを検証するために使用できます。例えば、ソースからの生データを処理する関数は、Pydanticモデルを返すようにデコレートすることができ、その出力が次のステージに渡される前にクリーンで構造化されていることを保証します。この文脈でのPydanticモデルは、データが期待に沿っていることを保証する「統一スキーマ」として機能し、バグが下流に伝播するのを防ぎます。[[polars-practical-analysis|Pandas DataFrame]]の行をモデルに変換してデータを検証する能力は、データサイエンスにおける強力なパターンです。

#### 設計思想：フェイルファストと検証可能なチェックポイント

このパターンは、データ品質に対する「フェイルファスト」アプローチを実装します。データ形式や内容のエラーは、パイプラインのずっと後の方で不可解な失敗を引き起こすのではなく、それが導入されたステージで即座に捕捉されます。各Pydanticモデルは検証可能なチェックポイントとして機能し、その時点でのデータがどうあるべきかについての明確なコントラクトを提供します。

#### 比較分析

* **vs. 専用データ品質ツール（例：Great Expectations, Soda-core）:** Great Expectationsのようなツールは、データセット全体（例：データベーステーブル全体やファイル）に対する大規模で宣言的なデータバリデーションのために設計されています。これらは静止したデータ（data-at-rest）の検証に優れています。一方、Pydanticは、Pythonアプリケーション内で処理されている最中の個々のレコードや小さなバッチの飛行中のデータ（in-flight）検証により適しています。これらは補完的な関係にあります。Pydanticは関数間で渡されるデータの構造的完全性を保証でき、Soda-coreのようなツールはデータがデータウェアハウスに格納された後にデータセット全体の統計的特性を検証できます。

### 2.5 新興パターン：生成AIのための構造化出力

#### コンテキストと目的

大規模言語モデル（LLM）の大きな課題の一つは、そのテキスト出力の予測不能性と非構造的な性質です。Pydanticチームはこの問題を認識し、Pydanticモデルを活用してLLMの出力を信頼性が高く、検証済みで、構造化された形式（JSON）に強制するフレームワークPydanticAIを開発しました。これは、本番品質のAIアプリケーションを構築する上で画期的な変化をもたらします。Pydanticの哲学が戦略的に拡張されていることは、「[[fastapi-evaluation-report|FastAPI]]の感覚をGenAIアプリ開発にもたらす」という目標に明確に示されています。これは、非構造的なWebリクエストを制御したPydanticの成功を、非構造的なLLM応答という新たな課題に結びつけるものです。

#### 設計思想：非決定性の制御

このパターンは、PydanticをAIに対する「補正レンズ」として使用します。モデルのJSONスキーマをプロンプトでLLMに提供することにより、モデルは望ましい構造に準拠した出力を生成するように誘導されます。その後、Pydanticがこの出力を検証し、検証に失敗した場合にはLLMにエラーフィードバック付きの再試行メカニズムを提供します。これにより、本質的に非決定的なプロセスに決定性と信頼性が課せられます。

#### 比較分析

* **vs. 手動の文字列パースと正規表現:** 代替案は、LLMの生のテキスト出力を手動でパースし、正規表現や複雑な文字列操作を使用することです。これは非常に脆弱で、LLMの出力のわずかな変動で壊れやすいです。Pydanticは、生成モデルから構造化データを抽出するための、はるかに堅牢で保守性が高く、強力なソリューションを提供します。

Pydanticの広範な採用は、単にその機能によるものではなく、Pythonプログラミングの異なるドメイン（API、設定、データパイプライン、AI）にわたってデータを記述するための統一的な「言語」を提供するためです。これは、データモデリングの事実上の標準を確立しています。API開発でPydanticに習熟したエンジニアは、その同じスキルセットを信頼性の高いAIアプリケーションやデータパイプラインの構築に適用できるようになり、これは開発者の生産性と部門横断的なコラボレーションにとって強力な推進力となります。

同様に、Pydanticとattrs間のパフォーマンス対柔軟性のトレードオフは、統合された意見の強いフレームワークと、柔軟なコンポーネントベースのライブラリとの間のソフトウェア設計における根本的な緊張関係を反映しています。どちらが「優れている」かという問題ではなく、これはアーキテクチャ上の決定です。利便性と堅牢な組み込みバリデーションが鍵となる外部向けの境界では、Pydanticがしばしば優れた選択肢となります。データがすでに信頼されているパフォーマンスが重要な内部ロジックでは、attrsエコシステムがよりきめ細かい制御と潜在的により高いパフォーマンスを提供します。

---

## 3.0 体系的なプロジェクト統合とベストプラクティス

本セクションでは、Pydanticを本番品質のPythonプロジェクトに統合するための、包括的で実践的なガイドを提供します。

### 3.1 包括的な設定と環境管理

#### BaseSettingsによる体系的なセットアップ

このセクションは、pydantic-settingsを使用するための実践的な青写真として機能します。

* **環境階層:** .envファイルを管理するためのベストプラクティス（例：ベースとなる.envファイルと、それを上書きする.env.local）と、設定ソースの明示的な優先順位。
* **ネストされた設定:** env_nested_delimiter（例：MYAPP_DATABASE__HOST）を使用して環境変数をネストされたPydanticモデルにマッピングし、クリーンで階層的な設定構造を作成するための詳細なガイド。
* **シークレット管理:** Docker/Kubernetes環境でsecrets_dir機能を使用するための実践的なアドバイスと、クラウドプロバイダー統合の概要。
* **CLI統合:** pydantic-settingsを使用して、コマンドライン引数が環境変数を上書きできるシンプルなCLIツールを構築し、統一された設定モデルを提供する方法。

### 3.2 プロジェクト構造とモデルの整理

#### 推奨されるディレクトリレイアウト

[[fastapi-evaluation-report|FastAPI]]プロジェクトのベストプラクティスに基づき、推奨される構造を提示します。

```
my_project/
├── src/
│   ├── api/
│   │   ├── v1/
│   │   │   ├── endpoints/
│   │   │   └── schemas.py  # このAPIバージョンのPydanticモデル
│   ├── core/
│   │   └── config.py   # BaseSettingsクラスの配置場所
│   ├── models/
│   │   └── user.py     # データベースモデル（例：SQLAlchemy, Django ORM）
│   └── schemas/
│       ├── __init__.py
│       ├── user.py     # userドメインに関連するPydanticモデル（スキーマ/DTO）
│       └── item.py
└── main.py
```

#### モデルの命名規則

特にCRUDコンテキストにおいて、モデルの目的を明確に伝えるための体系的な命名アプローチ。

* User: 共有フィールドを持つベースモデル。
* UserCreate: 新規ユーザー作成用モデル（例：パスワードを含む）。
* UserUpdate: ユーザー更新用モデル（例：すべてのフィールドがオプショナル）。
* UserInDB: データベースに保存されている完全なモデル（例：id、hashed_passwordを含む）。
* UserPublic: 公開APIエンドポイントから返されるモデル（例：hashed_passwordのような機密フィールドを除く）。

このモデル構造は単なる整理術ではなく、セキュリティとインターフェース分離の原則を直接実装するものです。例えば、ユーザー作成にはパスワードが必要ですが、APIクライアントにユーザー情報を返す際にはパスワードを含めるべきではありません。UserPublicのような個別のモデルを作成することで、インターフェース分離の原則（クライアントは使用しないインターフェースに依存すべきではない）を適用し、response_modelにUserPublicを設定することで、安全なフィールドのみがクライアントに送信されることを保証し、偶発的な機密データ漏洩を防ぎます。

#### 関心の分離

PydanticスキーマをデータベースORMモデルから分離するという重要な実践。PydanticモデルはAPI/DTOコントラクトを定義し、ORMモデルはデータベースコントラクトを定義します。この分離は保守性のために不可欠です。Pydanticのfrom_ormモード（現在はmodel_validate(..., from_attributes=True)）が、これら2つのレイヤー間の橋渡しとなります。

### 3.3 フレームワーク固有の統合ブループリント

#### FastAPI

* **基本を超えて:** 単純なリクエスト／レスポンスモデルを超えた活用法。複雑で再利用可能なバリデーションロジックのために、依存性注入内でPydanticモデルを使用する。
* **カスタムエラーハンドリング:** PydanticのValidationErrorを捕捉して、特定のAPIエラースキーマに準拠した、カスタムでユーザーフレンドリーなエラーレスポンスを作成する。
* **シリアライゼーションの最適化:** response_model_exclude_unsetやresponse_model_include/excludeパラメータを使用してAPIレスポンスを調整し、ペイロードサイズを削減する。

#### Django

* **[[../django/index_django.md|Django]]の近代化:** 従来の[[../django/index_django.md|Django]]プロジェクトにPydanticを統合するためのガイド。
  * **設定管理:** settings.pyの一部をPydanticのBaseSettingsクラスに置き換え、型安全で検証済みの設定を実現する。
  * **APIレイヤー:** 2つの主要なアプローチを議論します。
    1. **drf-pydantic:** 既存の[[../django/index_django.md|Django]] REST FrameworkプロジェクトにPydanticモデルを統合し、DRF Serializerのバリデーションおよびシリアライゼーションレイヤーとして機能させる。これは段階的な採用パスです。
    2. **django-ninja:** Pydantic上に構築された、[[fastapi-evaluation-report|FastAPI]]に触発されたモダンなフレームワークを使用する。これはDRFと並行して実行するか、完全に置き換えることができ、より良いパフォーマンスとモダンな開発体験を提供する。
  * **Pydantic vs. [[../django/index_django.md|Django]] Forms/Models:** それぞれの明確な役割。[[../django/index_django.md|Django]]モデルはデータベースレベルのバリデーションを扱います。[[../django/index_django.md|Django]]フォームはサーバーレンダリングされるHTMLフォーム用です。PydanticはAPIからの生データ（JSON）の扱いに優れており、この文脈ではDRF Serializerの優れた代替となります。

### 3.4 高度なテクニックと一般的な落とし穴

#### 効果的なバリデーターの使用法

* **適切なバリデータータイプの選択:** @field_validator対@model_validator、および異なるモード（'before', 'after', 'wrap'）の使い分け。
* クリーンで再利用可能なバリデーターを作成するためのベストプラクティス。

#### シリアライゼーションとデータ操作

* **エイリアス:** Field(alias='...')を使用して、Pythonicなsnake_caseのフィールド名と、外部のcamelCaseやkebab-caseのJSONキーとをマッピングし、外部の規約とやり取りしながらコードをクリーンに保つ。
* **計算済みフィールド:** @computed_fieldを使用して、シリアライズされた出力に含めるべき動的に計算されるプロパティを定義する。
* **きめ細かいシリアライゼーション制御:** model_dump()とmodel_dump_json()の引数（include, exclude, by_alias, exclude_none）を深く掘り下げ、出力を正確に制御する。

#### パフォーマンスとエッジケース

* **バリデーションの回避:** データが既に信頼されている場合（例：自社のデータベースから取得した場合）に、バリデーションを実行せずにモデルインスタンスを作成するためにmodel_construct()をいつ、なぜ使用するか。
* **代入時のバリデーション:** validate_assignmentモデル設定オプションを理解する。これは、インスタンス化後にフィールドの値が変更されるたびにバリデーションを再実行する。
* **再帰モデル:** 自己参照モデルの扱いと、前方参照を解決するためのmodel_rebuild()（旧update_forward_refs()）の重要性。

Pydantic V1からV2への進化、特にRustベースのpydantic-coreの導入は、単なる便利なPythonユーティリティから、Pythonエコシステムのための基礎的で高性能なデータインフラストラクチャレイヤーへの戦略的転換を表しています。このアーキテクチャ上の分離（Python向けのAPIと高性能エンジン）は、Pydanticが[[polars-practical-analysis|Polars]]や[[fastapi-evaluation-report|FastAPI]]のような他の高性能ライブラリの依存関係となり、データ集約的なパイプライン作業で真剣に受け止められるための前提条件でした。これは、Pydanticがもはや単なる「あれば便利」なツールではなく、他のツールが高性能でデータ認識型のアプリケーションを構築することを可能にする重要なインフラストラクチャであることを示しています。

## 4.0 結論

Pydanticは、単なるデータバリデーションライブラリの枠を超え、現代のPythonアプリケーション開発におけるデータハンドリングのパラダイムを再定義する、基礎的なツールへと進化しました。その核心は、型ヒントをランタイムの強制力を持つコントラクトへと変換し、「Parse, Don't Validate」の哲学を通じて、アプリケーションの境界でデータの信頼性を保証することにあります。

本分析で明らかになったように、Pydanticの価値は、API境界の強制、型安全な設定管理、内部サービス間のDTO、データパイプラインの整合性維持といった、多様なアーキテクチャパターンにわたって一貫して発揮されます。Rustで再実装されたコアエンジンは、パフォーマンスが重要な高スループットシステムでの採用を可能にし、Pydanticを便利なユーティリティから、エコシステムの他の主要ライブラリが依存する高性能なインフラストラクチャへと昇格させました。

技術リーダーやアーキテクトにとって、Pydanticを採用するという決定は、単一の機能を選択すること以上の意味を持ちます。それは、明示性、堅牢性、そして開発者の生産性を優先する設計思想を受け入れることを意味します。プロジェクトにPydanticを体系的に統合することは、コードの可読性を高め、保守を容易にし、データに起因するバグのクラス全体を排除することにつながります。特に[[fastapi-evaluation-report|FastAPI]]とのシームレスな統合や、生成AIの非構造化出力を制御する新興の応用例は、Pydanticが今後もPythonにおける構造化データ処理の中心であり続けることを示唆しています。したがって、Pydanticは、信頼性が高く、保守可能で、スケーラブルなPythonシステムを構築するための、戦略的に重要な選択肢であると結論付けられます。
